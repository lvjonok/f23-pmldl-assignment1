{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colorblind.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one’s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gargantua's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chad!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nuisance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99053</th>\n",
       "      <td>drawings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99054</th>\n",
       "      <td>slapshot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99055</th>\n",
       "      <td>anatoly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99056</th>\n",
       "      <td>secong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99057</th>\n",
       "      <td>shitty?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99058 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic_words\n",
       "0      colorblind.\n",
       "1            one’s\n",
       "2      gargantua's\n",
       "3            chad!\n",
       "4         nuisance\n",
       "...            ...\n",
       "99053     drawings\n",
       "99054    slapshot.\n",
       "99055   anatoly...\n",
       "99056       secong\n",
       "99057      shitty?\n",
       "\n",
       "[99058 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/interim/toxic_words.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK Stopwords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/leo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "try:\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK Stopwords\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "st = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "# function to clean data\n",
    "def clean_data(df, col, clean_col):\n",
    "    # change to lower and remove spaces on either side\n",
    "    df[clean_col] = df[col].apply(lambda x: str(x).lower().strip())\n",
    "\n",
    "    # remove extra spaces in between\n",
    "    df[clean_col] = df[clean_col].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "    # remove punctuation\n",
    "    df[clean_col] = df[clean_col].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "\n",
    "    # remove stopwords and get the stem\n",
    "    df[clean_col] = df[clean_col].apply(\n",
    "        lambda x: \" \".join(\n",
    "            st.stem(text) for text in x.split() if text not in stop_words\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_data(df, \"toxic_words\", \"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic_words</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colorblind.</td>\n",
       "      <td>colorblind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one’s</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gargantua's</td>\n",
       "      <td>gargantua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chad!</td>\n",
       "      <td>chad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nuisance</td>\n",
       "      <td>nuisanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99044</th>\n",
       "      <td>rejoyla</td>\n",
       "      <td>rejoyla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99048</th>\n",
       "      <td>mahalalo's</td>\n",
       "      <td>mahalalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99054</th>\n",
       "      <td>slapshot.</td>\n",
       "      <td>slapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99055</th>\n",
       "      <td>anatoly...</td>\n",
       "      <td>anatoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99056</th>\n",
       "      <td>secong</td>\n",
       "      <td>secong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic_words       clean\n",
       "0      colorblind.  colorblind\n",
       "1            one’s         one\n",
       "2      gargantua's   gargantua\n",
       "3            chad!        chad\n",
       "4         nuisance     nuisanc\n",
       "...            ...         ...\n",
       "99044      rejoyla     rejoyla\n",
       "99048   mahalalo's    mahalalo\n",
       "99054    slapshot.    slapshot\n",
       "99055   anatoly...     anatoli\n",
       "99056       secong      secong\n",
       "\n",
       "[35010 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the rows with the same 'clean' column\n",
    "df = df.drop_duplicates(subset=\"clean\", keep=\"first\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df.to_csv(\"../data/interim/toxic_words_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "Arguably, this vocabulary has many outliers and there are enough non-toxic words present.\n",
    "\n",
    "However, it is not a problem for idea of utilizing BERT for words replacement. Even though some non-toxic words from this vocabulary will be replaced, it will not create any toxicity either.\n",
    "\n",
    "Moreover, arguably the vocabulary should not be constructed from the whole dataset, but from the train dataset only. Otherwise, it will contain words from the test dataset, which is not good for the evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
