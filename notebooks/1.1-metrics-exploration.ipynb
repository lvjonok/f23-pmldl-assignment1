{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to explore the metrics of toxic words replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/github.com/lvjonok/f23-pmldl/f23-pmldl-assignment1/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15529/3552498662.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n",
      "Downloading builder script: 7.65kB [00:00, 4.44MB/s]                   \n"
     ]
    }
   ],
   "source": [
    "# Load the BLUE metric\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from previous notebook\n",
    "\n",
    "Original - `now you're getting nasty.`\n",
    "\n",
    "Transformed result - `now you're getting angry.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it {'score': 42.72870063962342, 'counts': [4, 2, 1, 0], 'totals': [5, 4, 3, 2], 'precisions': [80.0, 50.0, 33.333333333333336, 25.0], 'bp': 1.0, 'sys_len': 5, 'ref_len': 5}\n",
      "married {'score': 42.72870063962342, 'counts': [4, 2, 1, 0], 'totals': [5, 4, 3, 2], 'precisions': [80.0, 50.0, 33.333333333333336, 25.0], 'bp': 1.0, 'sys_len': 5, 'ref_len': 5}\n",
      "old {'score': 42.72870063962342, 'counts': [4, 2, 1, 0], 'totals': [5, 4, 3, 2], 'precisions': [80.0, 50.0, 33.333333333333336, 25.0], 'bp': 1.0, 'sys_len': 5, 'ref_len': 5}\n",
      "angry {'score': 42.72870063962342, 'counts': [4, 2, 1, 0], 'totals': [5, 4, 3, 2], 'precisions': [80.0, 50.0, 33.333333333333336, 25.0], 'bp': 1.0, 'sys_len': 5, 'ref_len': 5}\n",
      "better {'score': 42.72870063962342, 'counts': [4, 2, 1, 0], 'totals': [5, 4, 3, 2], 'precisions': [80.0, 50.0, 33.333333333333336, 25.0], 'bp': 1.0, 'sys_len': 5, 'ref_len': 5}\n"
     ]
    }
   ],
   "source": [
    "subs = [\"it\", \"married\", \"old\", \"angry\", \"better\"]\n",
    "\n",
    "original = \"Now you're getting nasty.\"\n",
    "\n",
    "for sub in subs:\n",
    "    transformed = original.replace(\"nasty\", sub)\n",
    "    # Compute the score\n",
    "    score = metric.compute(predictions=[transformed], references=[[original]])\n",
    "\n",
    "    print(sub, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It can be seen that it is not quite useful to use BLEU metric to evaluate the performance of the model.\n",
    "\n",
    "1. This approach does not require fine tune of BERT model, so there is no need to use metrics for train process.\n",
    "1. In the previous notebook we have chosen what will be substituted by similarity, so we will use it as the metric that sentence is similar to the original one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuation idea:\n",
    "\n",
    "There is a [model](https://huggingface.co/mohsenfayyaz/toxicity-classifier?text=Motherfucker) which classifies sentence into toxic/non-toxic.\n",
    "\n",
    "We might utilize it to evaluate how many toxic sentences are left here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
